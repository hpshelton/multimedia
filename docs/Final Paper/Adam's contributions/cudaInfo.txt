	Dedicated graphical processing units (GPU) have become more prevalent in modern computers. This specialized hardware differs from traditional CPUs in that it is designed to preform parallel arithmetic computations. While the GPU is almost always used for 3D intensive applications, such as gaming, it is rarely tapped into for general computing tasks. In order to use this computational power in a general computing environment, NVIDIA has developed Compute Unified Device Architecture (CUDA). CUDA enabled code can be executed on all of NVIDIA's modern GPUs (developed in the past three years). These include the consumer GeForce series, the professional Quadro and Tesla cards, and even the ION series of GPUs, found in netbooks and small form factor media centers.
	CUDA allows the programmer to allocate the GPU's multiprocessors in order to run parallel computations. A GPU's hardware is divided into blocks and threads. Each block contains a fixed amount of threads, and each thread is capable of running one calculation. Each active thread must run the same calculation, but each thread may preform the calculation on a different value in memory.
	Memory is not shared by the GPU and the CPU. Memory must be copied from the host (CPU) to the device (GPU) when a calculation must be preformed. This memory transfer runs in O(n) time. Because memory must be copied, certain operations such as matrix subtraction are not well suited to be parallelized. A matrix subtraction on the GPU would take O(n) time for the memory transfer and O(n/threads) time for the operation, whereas whereas the same operation on the CPU will take O(n) time.
	Memory on the GPU is divided into global memory, which is accessible from each thread in each block, shared memory, which is accessible from each thread in a given block, but not threads in other blocks, and register memory, which is only accessible from a single thread. Registers are accessed faster than shared memory, which is in turn accessed faster than global memory. When data is moved from the CPU to the GPU, it is placed in global memory.

	The two compression algorithms that were implemented in a parallel fashion were the biorthogonal 9/7 discrete wavelet transform (DWT) with a dead-zone quantizer for images and a closed-loop DPCM quantizer with motion estimation for videos.
	The particular implementation of the DWT that was used was the lifting implementation. This implementation is the same one used in the JPEG2000 standard. The transform works on an array of real values. The values are filtered into low and high frequency subbands, which are each downsampled by a factor of two. The high pass subband is retained in the odd indices of the array, while the low pass subband is retained in the even indices of the array. The inverse transform is preformed using the same computational structure, but with inverse filters.
	A sketch of the algorithm for image transformation is as follows. First, the image is transfered into GPU memory. The different color components must be transformed separately, so the image data, which is stored in 0xffRRGGBB 32 bit fields rearranged such that all the red, blue, and green values are in continuous memory. This is done in one parallel step, where each thread moves one color value, and is not done in-place. Each row of each continuous color region is then transformed in parallel. Due to the iterative nature of the FWT, the algorithm cannot be preformed in one step. Once each row is transformed, each continuous color region is transposed, separately. The FWT is then applied to each row (previously column) of each continuous color region in parallel. This completes the one level 2D FWT. Another transpose, FWT, transpose, and FWT may be applied to preform the two level 2D FWT.
	The inverse transform is simply the same process in reverse using the iFWT instead of the FWT, and rearranging continuous color regions into 32 bit 0xffRRGGBB fields.
	A sketch of the algorithm for video transformation is as follows. For the first frame, the previous frame is set to all zeros. The encoded previous frame is subtracted from the current frame, d[n], which is then quantized and inverse quantized, d_hat[n]. This value is summed with the encoded previous frame, x_hat[n-1] and set as the new encoded previous frame for the next iteration, x_hat[n]. Motion vectors are then found for each 8x8 block which minimize the matrix x[n] - x_hat[n-1] + motion vectors, and the quantized result along with the motion vectors are sent to the communication channel.
	Decoding is simpler than encoding, and simply involves summing the previous decoded frame, x_hat[n-1], shifted by motion vectors, with the inverse quantized incoming frame, d_hat[n].
	The parallelization comes into play with the search for optimal motion vectors. As previously stated, simple operations such as matrix addition or subtraction do not offer significant speedup when preformed on the GPU. An exhaustive search for motion vectors lends itself well to parallelization. Each block on the GPU is assigned one 8x8 block of pixels out of the frame and the previous 8x8 block of pixels out of the frame, and each thread within that block calculates one potential motion vector and the resulting sum of the absolute value of the difference between blocks. From this pool of all motion vectors, a parallel reduction is preformed. Serially, to find the minimum value in an array, O(n) time is taken. Parallely, it is not possible to compare all values at once, but the search can be reduced to O(log(n)) time. The first iteration of the reduction compares n/2 sets of 2 elements, and returns the smallest of each. The next iteration then only has to compare n/4 sets of 2 elements, and returns the smallest of each. This continues until the smallest element is found. In this case, the motion vector with the smallest difference is found, and returned.
	Sample code which came with the CUDA SDK was modified and used for the reduction and the transpose. A second set of non-parallelized algorithms are also supplied to compare with GPU accelerated algorithms, and for users who do not have a compatible GPU.
